<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>

<property>
  <name>key.serializer</name>
  <description>
    Serializer class for key that implements the org.apache.kafka.common.serialization.Serializer interface.
  </description>
  <cn_description>
    指定Key序列化使用的类
  </cn_description>
  <type>class</type>
  <default></default>
  <valid_values></valid_values>
  <importance>high</importance>
  <suggest></suggest>
</property>

<property>
  <name>value.serializer</name>
  <description>
    Serializer class for value that implements the org.apache.kafka.common.serialization.Serializer interface.
  </description>
  <cn_description>
    指定Value序列化使用的类
  </cn_description>
  <type>class</type>
  <default></default>
  <valid_values></valid_values>
  <importance>high</importance>
  <suggest></suggest>
</property>

<property>
  <name>acks</name>
  <description>
    The number of acknowledgments the producer requires the leader to have received before considering a request complete.
    This controls the durability of records that are sent. The following settings are allowed:

      acks=0 If set to zero then the producer will not wait for any acknowledgment from the server at all.
        The record will be immediately added to the socket buffer and considered sent.
        No guarantee can be made that the server has received the record in this case, and the retries configuration will not take effect
        (as the client won't generally know of any failures).
        The offset given back for each record will always be set to -1.
      acks=1 This will mean the leader will write the record to its local log but will respond without awaiting full acknowledgement from all followers.
        In this case should the leader fail immediately after acknowledging the record but before the followers have replicated it then the record will be lost.
      acks=all This means the leader will wait for the full set of in-sync replicas to acknowledge the record.
        This guarantees that the record will not be lost as long as at least one in-sync replica remains alive.
        This is the strongest available guarantee. This is equivalent to the acks=-1 setting.
  </description>
  <cn_description>Producer在确认一个发送完成之前需要收到的反馈信息的数量</cn_description>
  <type>string</type>
  <default>1</default>
  <valid_values>[all, -1, 0, 1]</valid_values>
  <importance>high</importance>
  <suggest>
    0 producer不会等待任何反馈就会认为记录发送完成。此时retry属性无效，且记录返回的offset被设置为-1
    1 与 all/-1相反的情况，leader节点保存记录以后会马上反馈记录是否发送完成，如果反馈完成以后，follow同步副本失败，则会出现记录丢失的情况。
    all/-1  leader节点确认所有follow同步完成后，再反馈记录是否发送完成。该属性可靠性最高，但是相对来说响应时间更慢，因为需要等待所以节点完成同步。
    （ps:如果其中一个节点同步失败，leader就会反馈发送失败，producer就会重新尝试发送）
  </suggest>
</property>

<property>
  <name>bootstrap.servers</name>
  <description>
    A list of host/port pairs to use for establishing the initial connection to the Kafka cluster.
      The client will make use of all servers irrespective of which servers are specified here for bootstrapping—this list only impacts the initial hosts used to discover the full set of servers.
      This list should be in the form host1:port1,host2:port2,.... Since these servers are just used for the initial connection to discover the full cluster membership (which may change dynamically),
    this list need not contain the full set of servers (you may want more than one, though, in case a server is down).
  </description>
  <cn_description>
    用于与Kafka集群客户端进行初始化连接，连接成功以后，客户端会负责负载均衡的与集群中所有机器建立连接
  </cn_description>
  <type>list</type>
  <default>""</default>
  <valid_values>
    org.apache.kafka.common.config.ConfigDef$
    NonNullValidator@7cd62f43
  </valid_values>
  <importance>high</importance>
  <suggest></suggest>
</property>

<property>
  <name>buffer.memory</name>
  <description>
    The total bytes of memory the producer can use to buffer records waiting to be sent to the server.
    If records are sent faster than they can be delivered to the server the producer will block for max.block.ms after which it will throw an exception.
    This setting should correspond roughly to the total memory the producer will use, but is not a hard bound since not all memory the producer uses is used for buffering.
    Some additional memory will be used for compression (if compression is enabled) as well as for maintaining in-flight requests.
  </description>
  <cn_description>
    该参数用来设置生产者内存缓冲区的大小，生产者用它缓冲要发送到服务器的消息。
    如果应用程序发送消息的速度超过发送到服务器的速度，会导致生产者空间不足。
    这个时候，send() 方法调用要么被阻塞，要么抛出异常，取决于如何设置 block.on.buffe.full 参数（在0.9.0.0 版本里被替换成了 max.block.ms ，表示在抛出异常之前可以阻塞一段时间）。
  </cn_description>
  <type>long</type>
  <default>33554432</default>
  <valid_values>[0,...]</valid_values>
  <importance>high</importance>
  <suggest></suggest>
</property>

<property>
  <name>compression.type</name>
  <description>
    The compression type for all data generated by the producer.
    The default is none (i.e. no compression).
    Valid values are none, gzip, snappy, or lz4. Compression is of full batches of data, so the efficacy of batching will also impact the compression ratio (more batching means better compression).
  </description>
  <cn_description>
    默认情况下，消息发送时不会被压缩。
    该参数可以设置成 snappy，gzip或lz4，它指定了消息发送给 broker 之前使用哪一种压缩算法。
    snappy压缩算法由 Google 发明，它占用较少的CPU，却能提供较好的性能和相当可观的压缩比，如果比较关注性能和网络带宽，可以使用这种压缩算法。
    gzip压缩算法一般会占用比较多的CPU，但会提供更高的压缩，所以如果网络带宽有限，可以使用这种算法。
    使用压缩可以降低网络传输开销和存储开销，而这往往是向kafka发送消息的瓶颈所在。
  </cn_description>
  <type>string</type>
  <default>none</default>
  <valid_values>none,gzip,snappy,lz4</valid_values>
  <importance>high</importance>
  <suggest></suggest>
</property>

<property>
  <name>retries</name>
  <description>
    Setting a value greater than zero will cause the client to resend any record whose send fails with a potentially transient error.
      Note that this retry is no different than if the client resent the record upon receiving the error.
      Allowing retries without setting max.in.flight.requests.per.connection to 1 will potentially change the ordering of records because if two batches are sent to a single partition,
    and the first fails and is retried but the second succeeds, then the records in the second batch may appear first.
  </description>
  <cn_description>
    发送失败的记录重新发送的次数，max.in.flight.requests.per.connection 大于 1 时可能会导致发送的顺序发生改变。
    即 先后发送 A、B记录，而A失败，B成功时。B的顺序会先于A
  </cn_description>
  <type>int</type>
  <default>0</default>
  <valid_values>[0,...,2147483647]</valid_values>
  <importance>high</importance>
  <suggest></suggest>
</property>

<property>
  <name>ssl.key.password</name>
  <description>
    The password of the private key in the key store file. This is optional for client.
  </description>
  <cn_description></cn_description>
  <type>password</type>
  <default>null</default>
  <valid_values></valid_values>
  <importance>high</importance>
  <suggest></suggest>
</property>

<property>
  <name>ssl.keystore.location</name>
  <description>
    The location of the key store file. This is optional for client and can be used for two-way authentication for client.
  </description>
  <cn_description></cn_description>
  <type>string</type>
  <default>null</default>
  <valid_values></valid_values>
  <importance>high</importance>
  <suggest></suggest>
</property>

<property>
  <name>ssl.keystore.password</name>
  <description>
    The store password for the key store file. This is optional for client and only needed if ssl.keystore.location is configured.
  </description>
  <cn_description></cn_description>
  <type>password</type>
  <default>null</default>
  <valid_values></valid_values>
  <importance>high</importance>
  <suggest></suggest>
</property>

<property>
  <name>ssl.truststore.location</name>
  <description>
    The location of the trust store file.
  </description>
  <cn_description></cn_description>
  <type>string</type>
  <default>null</default>
  <valid_values></valid_values>
  <importance>high</importance>
  <suggest></suggest>
</property>

<property>
  <name>ssl.truststore.password</name>
  <description>
    The password for the trust store file. If a password is not set access to the truststore is still available, but integrity checking is disabled.
  </description>
  <cn_description></cn_description>
  <type>password</type>
  <default>null</default>
  <valid_values></valid_values>
  <importance>high</importance>
  <suggest></suggest>
</property>

<property>
  <name>batch.size</name>
  <description>
    The producer will attempt to batch records together into fewer requests whenever multiple records are being sent to the same partition.
    This helps performance on both the client and the server. This configuration controls the default batch size in bytes.
      No attempt will be made to batch records larger than this size.
      Requests sent to brokers will contain multiple batches, one for each partition with data available to be sent.
      A small batch size will make batching less common and may reduce throughput (a batch size of zero will disable batching entirely).
      A very large batch size may use memory a bit more wastefully as we will always allocate a buffer of the specified batch size in anticipation of additional records.
  </description>
  <cn_description>
    producer将试图成批地处理消息记录，以减少请求次数。这将改善client与server之间的性能。 这项配置控制默认的批量处理消息字节数。不会试图处理大于这个字节数的消息字节数。
    发送到brokers的请求将包含多个批量处理，其中会包含对每个partition的一个请求。较小的批量处理数值比较少用，并且可能降低吞吐量（0则会禁用批量处理）。
    较大的批量处理数值将会浪费更多内存空间，这样就需要分配特定批量处理数值的内存大小
  </cn_description>
  <type>int</type>
  <default>16384</default>
  <valid_values>[0,...]</valid_values>
  <importance>medium</importance>
  <suggest>524288</suggest>
</property>

<property>
  <name>client.id</name>
  <description>
    An id string to pass to the server when making requests.
    The purpose of this is to be able to track the source of requests beyond just ip/port by allowing a logical application name to be included in server-side request logging.
  </description>
  <cn_description>发出请求时传递给服务器的 id 字符串。这样做的目的是通过允许将逻辑应用程序名称包含在服务器端请求日志记录中，从而能够跟踪请求源，而不仅仅是 ip/端口。</cn_description>
  <type>string</type>
  <default>""</default>
  <valid_values></valid_values>
  <importance>medium</importance>
  <suggest></suggest>
</property>

<property>
  <name>connections.max.idle.ms</name>
  <description>
    Close idle connections after the number of milliseconds specified by this config.
  </description>
  <cn_description>
     在此配置指定的毫秒数之后关闭空闲连接。
  </cn_description>
  <type>long</type>
  <default>540000</default>
  <valid_values></valid_values>
  <importance>medium</importance>
  <suggest></suggest>
</property>

<property>
  <name>linger.ms</name>
  <description>
    The producer groups together any records that arrive in between request transmissions into a single batched request.

      Normally this occurs only under load when records arrive faster than they can be sent out.
      However in some circumstances the client may want to reduce the number of requests even under moderate load.
      This setting accomplishes this by adding a small amount of artificial delay—that is,
    rather than immediately sending out a record the producer will wait for up to the given delay to allow other records to be sent so that the sends can be batched together.
      This can be thought of as analogous to Nagle's algorithm in TCP.
      This setting gives the upper bound on the delay for batching: once we get batch.size worth of records for a partition it will be sent immediately regardless of this setting,
    however if we have fewer than this many bytes accumulated for this partition we will 'linger' for the specified time waiting for more records to show up.
      This setting defaults to 0 (i.e. no delay). Setting linger.ms=5, for example,
    would have the effect of reducing the number of requests sent but would add up to 5ms of latency to records sent in the absence of load.
  </description>
  <cn_description>
    该参数指定了生产者在发送批次之前等待更多消息加入批次的时间。
    KafkaProducer 会在批次填满或 linger.ms 达到上限时把批次发送出去。默认情况下，只要有可用的线程，就算批次里只有一个消息，生产者也会把消息发送出去。
    把 linger.ms 设置成大于0的数，让生产者在发送批次前等一会，使更多的消息加入这个批次，虽然这样做会增加延迟，但也会提高吞吐量。
  </cn_description>
  <type>long</type>
  <default>0</default>
  <valid_values>[0,...]</valid_values>
  <importance>medium</importance>
  <suggest></suggest>
</property>

<property>
  <name>max.block.ms</name>
  <description>
    The configuration controls how long KafkaProducer.send() and KafkaProducer.partitionsFor() will block.
    These methods can be blocked either because the buffer is full or metadata unavailable.Blocking in the user-supplied serializers or partitioner will not be counted against this timeout.
  </description>
  <cn_description>
    控制 KafkaProducer.send() 和 KafkaProducer.partitionsFor() 允许被阻塞的时长。
    因记录序列化或者元数据丢失而阻塞的情况，不会计算到此超时。
  </cn_description>
  <type>long</type>
  <default>60000</default>
  <valid_values>[0,...]</valid_values>
  <importance>medium</importance>
  <suggest></suggest>
</property>

<property>
  <name>max.request.size</name>
  <description>
    The maximum size of a request in bytes. This setting will limit the number of record batches the producer will send in a single request to avoid sending huge requests.
    This is also effectively a cap on the maximum record batch size. Note that the server has its own cap on record batch size which may be different from this.
  </description>
  <cn_description>
    该参数用于控制生产者发送的请求大小，它可以指定能发送的单个消息的最大值，也可以指单个请求里所有消息的总大小。
    例如，假设这个值为 1MB，那么可以发送的单个最大消息为 1MB ，或者生产者可以在单个请求里发送一个批次，该批次包含了 1000 个消息，每个消息大小为 1KB。
    另外， broker 对可接收的消息最大值也有自己的限制（message.max.bytes），所以两边的配置最好可以匹配，避免生产者发送的消息被 broker 拒绝。
  </cn_description>
  <type>int</type>
  <default>1048576</default>
  <valid_values>[0,...]</valid_values>
  <importance>medium</importance>
  <suggest></suggest>
</property>

<property>
  <name>partitioner.class</name>
  <description>
    Partitioner class that implements the org.apache.kafka.clients.producer.Partitioner interface.
  </description>
  <cn_description>
    自定义分区策略，实现接口 org.apache.kafka.clients.producer.Partitioner，默认值：org.apache.kafka.clients.producer.internals.DefaultPartitioner
  </cn_description>
  <type>class</type>
  <default>
    org.apache.kafka.clients.producer.
    internals.DefaultPartitioner
  </default>
  <valid_values></valid_values>
  <importance>medium</importance>
  <suggest></suggest>
</property>

<property>
  <name>receive.buffer.bytes</name>
  <description>
    The size of the TCP receive buffer (SO_RCVBUF) to use when reading data. If the value is -1, the OS default will be used.
  </description>
  <cn_description>
    TCP receive缓存大小，当读取数据时使用
  </cn_description>
  <type>int</type>
  <default>32768</default>
  <valid_values>[-1,...]</valid_values>
  <importance>medium</importance>
  <suggest>默认值</suggest>
</property>

<property>
  <name>request.timeout.ms</name>
  <description>
    The configuration controls the maximum amount of time the client will wait for the response of a request.
      If the response is not received before the timeout elapses the client will resend the request if necessary or fail the request if retries are exhausted.
      This should be larger than replica.lag.time.max.ms (a broker configuration) to reduce the possibility of message duplication due to unnecessary producer retries.
  </description>
  <cn_description>
    request.timeout.ms 指定了生产者在发送数据时等待服务器返回响应的时间
  </cn_description>
  <type>int</type>
  <default>30000</default>
  <valid_values>[0,...]</valid_values>
  <importance>medium</importance>
  <suggest></suggest>
</property>

<property>
  <name>sasl.client.callback.handler.class</name>
  <description>
    The fully qualified name of a SASL client callback handler class that implements the AuthenticateCallbackHandler interface.
  </description>
  <cn_description></cn_description>
  <type>class</type>
  <default>null</default>
  <valid_values></valid_values>
  <importance>medium</importance>
  <suggest></suggest>
</property>

<property>
  <name>sasl.jaas.config</name>
  <description>
    JAAS login context parameters for SASL connections in the format used by JAAS configuration files.
      JAAS configuration file format is described here.
      The format for the value is: 'loginModuleClass controlFlag (optionName=optionValue)*;'.
    For brokers, the config must be prefixed with listener prefix and SASL mechanism name in lower-case.
    For example, listener.name.sasl_ssl.scram-sha-256.sasl.jaas.config=com.example.ScramLoginModule required;
  </description>
  <cn_description></cn_description>
  <type>password</type>
  <default>null</default>
  <valid_values></valid_values>
  <importance>medium</importance>
  <suggest></suggest>
</property>

<property>
  <name>sasl.kerberos.service.name</name>
  <description>
    The Kerberos principal name that Kafka runs as. This can be defined either in Kafka's JAAS config or in Kafka's config.
  </description>
  <cn_description></cn_description>
  <type>string</type>
  <default>null</default>
  <valid_values></valid_values>
  <importance>medium</importance>
  <suggest></suggest>
</property>

<property>
  <name>sasl.login.callback.handler.class</name>
  <description>
    The fully qualified name of a SASL login callback handler class that implements the AuthenticateCallbackHandler interface.
      For brokers, login callback handler config must be prefixed with listener prefix and SASL mechanism name in lower-case.
      For example, listener.name.sasl_ssl.scram-sha-256.sasl.login.callback.handler.class=com.example.CustomScramLoginCallbackHandler
  </description>
  <cn_description></cn_description>
  <type>class</type>
  <default>null</default>
  <valid_values></valid_values>
  <importance>medium</importance>
  <suggest></suggest>
</property>

<property>
  <name>sasl.login.class</name>
  <description>
    The fully qualified name of a class that implements the Login interface.
    For brokers, login config must be prefixed with listener prefix and SASL mechanism name in lower-case.
    For example, listener.name.sasl_ssl.scram-sha-256.sasl.login.class=com.example.CustomScramLogin
  </description>
  <cn_description></cn_description>
  <type>class</type>
  <default>null</default>
  <valid_values></valid_values>
  <importance>medium</importance>
  <suggest></suggest>
</property>

<property>
  <name>sasl.mechanism</name>
  <description>
    SASL mechanism used for client connections. This may be any mechanism for which a security provider is available. GSSAPI is the default mechanism.
  </description>
  <cn_description></cn_description>
  <type>string</type>
  <default>GSSAPI</default>
  <valid_values></valid_values>
  <importance>medium</importance>
  <suggest></suggest>
</property>

<property>
  <name>security.protocol</name>
  <description>
    Protocol used to communicate with brokers. Valid values are: PLAINTEXT, SSL, SASL_PLAINTEXT, SASL_SSL.
  </description>
  <cn_description></cn_description>
  <type>string</type>
  <default>PLAINTEXT</default>
  <valid_values></valid_values>
  <importance>medium</importance>
  <suggest></suggest>
</property>

<property>
  <name>send.buffer.bytes</name>
  <description>
    The size of the TCP send buffer (SO_SNDBUF) to use when sending data. If the value is -1, the OS default will be used.
  </description>
  <cn_description>
    TCP send缓存大小，当发送数据时使用
  </cn_description>
  <type>int</type>
  <default>131072</default>
  <valid_values>[-1,...]</valid_values>
  <importance>medium</importance>
  <suggest>默认值或者略大于带宽*时延</suggest>
</property>

<property>
  <name>ssl.enabled.protocols</name>
  <description>
    The list of protocols enabled for SSL connections.
  </description>
  <cn_description></cn_description>
  <type>list</type>
  <default>TLSv1.2,TLSv1.1,TLSv1</default>
  <valid_values></valid_values>
  <importance>medium</importance>
  <suggest></suggest>
</property>

<property>
  <name>ssl.keystore.type</name>
  <description>
    The file format of the key store file. This is optional for client.
  </description>
  <cn_description></cn_description>
  <type>string</type>
  <default>JKS</default>
  <valid_values></valid_values>
  <importance>medium</importance>
  <suggest></suggest>
</property>

<property>
  <name>ssl.protocol</name>
  <description>
    The SSL protocol used to generate the SSLContext. Default setting is TLS, which is fine for most cases.
    Allowed values in recent JVMs are TLS, TLSv1.1 and TLSv1.2. SSL, SSLv2 and SSLv3 may be supported in older JVMs, but their usage is discouraged due to known security vulnerabilities.
  </description>
  <cn_description></cn_description>
  <type>string</type>
  <default>TLS</default>
  <valid_values></valid_values>
  <importance>medium</importance>
  <suggest></suggest>
</property>

<property>
  <name>ssl.provider</name>
  <description>
    The name of the security provider used for SSL connections. Default value is the default security provider of the JVM.
  </description>
  <cn_description></cn_description>
  <type>string</type>
  <default>null</default>
  <valid_values></valid_values>
  <importance>medium</importance>
  <suggest></suggest>
</property>

<property>
  <name>ssl.truststore.type</name>
  <description>
    The file format of the trust store file.
  </description>
  <cn_description></cn_description>
  <type>string</type>
  <default>JKS</default>
  <valid_values></valid_values>
  <importance>medium</importance>
  <suggest></suggest>
</property>

<property>
  <name>enable.idempotence</name>
  <description>
    When set to 'true', the producer will ensure that exactly one copy of each message is written in the stream.
    If 'false', producer retries due to broker failures, etc., may write duplicates of the retried message in the stream.
    Note that enabling idempotence requires max.in.flight.requests.per.connection to be less than or equal to 5, retries to be greater than 0 and acks must be 'all'.
    If these values are not explicitly set by the user, suitable values will be chosen. If incompatible values are set, a ConfigException will be thrown.
  </description>
  <cn_description>
    当设置为“true”时，生产者将确保在流中准确地写入每个消息的副本。
    如果“false”，则由于代理失败而导致生产者重试，等等，可能会在流中写入重试消息的副本。
    请注意，启用幂等需要使用max.in.flight.requests.per.connection,连接小于或等于5，重试大于0且ack必须为“all”。
    如果用户没有显式地设置这些值，将选择合适的值。
    如果设置了不兼容的值，就会抛出ConfigException。
  </cn_description>
  <type>boolean</type>
  <default>false</default>
  <valid_values></valid_values>
  <importance>low</importance>
  <suggest></suggest>
</property>

<property>
  <name>interceptor.classes</name>
  <description>
    A list of classes to use as interceptors.
    Implementing the org.apache.kafka.clients.producer.ProducerInterceptor interface allows you to intercept (and possibly mutate) the records received by the producer before they are published to the Kafka cluster.
    By default, there are no interceptors.
  </description>
  <cn_description>
    用作拦截器的类的列表。实现接口：org.apache.kafka.clients.producer。
    ProducerInterceptor接口允许将生产者接收到的记录发布到Kafka集群之前拦截它们(可能还会发生突变)。
    默认情况下，没有拦截器。
  </cn_description>
  <type>list</type>
  <default>""</default>
  <valid_values>
    org.apache.kafka.common.config.ConfigDef$
    NonNullValidator@6d4b1c02
  </valid_values>
  <importance>low</importance>
  <suggest></suggest>
</property>

<property>
  <name>max.in.flight.requests.per.connection</name>
  <description>
    The maximum number of unacknowledged requests the client will send on a single connection before blocking.
    Note that if this setting is set to be greater than 1 and there are failed sends, there is a risk of message re-ordering due to retries (i.e., if retries are enabled).
  </description>
  <cn_description>
    该参数指定了生产者在收到服务器响应之前可以发送多少消息。
    它的值越高，就会占用越多的内存，不过也会提升吞吐量。
    把它设为1可以保证消息是按照发送的顺序写入服务器的，即使发生了重试。</cn_description>
  <type>int</type>
  <default>5</default>
  <valid_values>[1,...]</valid_values>
  <importance>low</importance>
  <suggest></suggest>
</property>

<property>
  <name>max.in.flight.requests.per.connection</name>
  <description>
    The maximum number of unacknowledged requests the client will send on a single connection before blocking.
    Note that if this setting is set to be greater than 1 and there are failed sends, there is a risk of message re-ordering due to retries (i.e., if retries are enabled).
  </description>
  <cn_description>
    该参数指定了生产者在收到服务器响应之前可以发送多少消息。
    它的值越高，就会占用越多的内存，不过也会提升吞吐量。
    把它设为1可以保证消息是按照发送的顺序写入服务器的，即使发生了重试。
  </cn_description>
  <type>int</type>
  <default>5</default>
  <valid_values>[1,...]</valid_values>
  <importance>low</importance>
  <suggest></suggest>
</property>

<property>
  <name>metadata.max.age.ms</name>
  <description>
    The period of time in milliseconds after which we force a refresh of metadata even if we haven't seen any partition leadership changes to proactively discover any new brokers or partitions.
  </description>
  <cn_description>
    这个参数用来配置元数据的过期时间，默认值为300000（ms），即5分钟。
    如果元数据在此参数所限定的时间范围内没有进行更新，则会被强制更新，即使没有任何分区变化或有新的 broker 加入。
  </cn_description>
  <type>long</type>
  <default>300000</default>
  <valid_values>[0,...]</valid_values>
  <importance>low</importance>
  <suggest></suggest>
</property>

<property>
  <name>metric.reporters</name>
  <description>
    A list of classes to use as metrics reporters. Implementing the org.apache.kafka.common.metrics.MetricsReporter interface allows plugging in classes that will be notified of new metric creation.
    The JmxReporter is always included to register JMX statistics.
  </description>
  <cn_description>
    用作指标报告器的类的列表。
    metricsreporter接口实现了org.apache.kafka.common.metrics.MetricsReporter接口，该接口允许插入将在创建新度量时得到通知的类。JmxReporter始终包含在注册JMX统计信息中。
  </cn_description>
  <type>list</type>
  <default>""</default>
  <valid_values>
    org.apache.kafka.common.config.ConfigDef$
    NonNullValidator@6093dd95
  </valid_values>
  <importance>low</importance>
  <suggest></suggest>
</property>

<property>
  <name>metrics.num.samples</name>
  <description>
    The number of samples maintained to compute metrics.
  </description>
  <cn_description></cn_description>
  <type>int</type>
  <default>2</default>
  <valid_values>[1,...]</valid_values>
  <importance>low</importance>
  <suggest></suggest>
</property>

<property>
  <name>metrics.recording.level</name>
  <description>
    The highest recording level for metrics.
  </description>
  <cn_description></cn_description>
  <type>string</type>
  <default>INFO</default>
  <valid_values>[INFO, DEBUG]</valid_values>
  <importance>low</importance>
  <suggest></suggest>
</property>

<property>
  <name>metrics.sample.window.ms</name>
  <description>
    The window of time a metrics sample is computed over.
  </description>
  <cn_description></cn_description>
  <type>long</type>
  <default>30000</default>
  <valid_values>[0,...]</valid_values>
  <importance>low</importance>
  <suggest></suggest>
</property>

<property>
  <name>reconnect.backoff.max.ms</name>
  <description>
    The maximum amount of time in milliseconds to wait when reconnecting to a broker that has repeatedly failed to connect.
    If provided, the backoff per host will increase exponentially for each consecutive connection failure, up to this maximum.
    After calculating the backoff increase, 20% random jitter is added to avoid connection storms.
  </description>
  <cn_description>
    重新建立链接的最大等待时长，默认为1s，连续两次对同一个连接建立重连，等待时间会在reconnect.backoff.ms的初始值上成指数级递增，但超过max后，将不再指数级递增。
  </cn_description>
  <type>long</type>
  <default>1000</default>
  <valid_values>[0,...]</valid_values>
  <importance>low</importance>
  <suggest></suggest>
</property>

<property>
  <name>retry.backoff.ms</name>
  <description>
    The amount of time to wait before attempting to retry a failed request to a given topic partition. This avoids repeatedly sending requests in a tight loop under some failure scenarios.
  </description>
  <cn_description>
     重试间隔时间，默认为100ms。这避免了在某些失败场景下以紧密循环的方式重复发送请求。
  </cn_description>
  <type>long</type>
  <default>100</default>
  <valid_values>[0,...]</valid_values>
  <importance>low</importance>
  <suggest></suggest>
</property>

<property>
  <name>sasl.kerberos.kinit.cmd</name>
  <description>
    Kerberos kinit command path.
  </description>
  <cn_description></cn_description>
  <type>string</type>
  <default>/usr/bin/kinit</default>
  <valid_values></valid_values>
  <importance>low</importance>
  <suggest></suggest>
</property>

<property>
  <name>sasl.kerberos.min.time.before.relogin</name>
  <description>
    Login thread sleep time between refresh attempts.
  </description>
  <cn_description></cn_description>
  <type>long</type>
  <default>60000</default>
  <valid_values></valid_values>
  <importance>low</importance>
  <suggest></suggest>
</property>

<property>
  <name>sasl.kerberos.ticket.renew.jitter</name>
  <description>
    Percentage of random jitter added to the renewal time.
  </description>
  <cn_description></cn_description>
  <type>double</type>
  <default>0.05</default>
  <valid_values></valid_values>
  <importance>low</importance>
  <suggest></suggest>
</property>

<property>
  <name>sasl.kerberos.ticket.renew.window.factor</name>
  <description>
    Login thread will sleep until the specified window factor of time from last refresh to ticket's expiry has been reached, at which time it will try to renew the ticket.
  </description>
  <cn_description></cn_description>
  <type>double</type>
  <default>0.8</default>
  <valid_values></valid_values>
  <importance>low</importance>
  <suggest></suggest>
</property>

<property>
  <name>sasl.login.refresh.buffer.seconds</name>
  <description>
    The amount of buffer time before credential expiration to maintain when refreshing a credential, in seconds.
    If a refresh would otherwise occur closer to expiration than the number of buffer seconds then the refresh will be moved up to maintain as much of the buffer time as possible.
    Legal values are between 0 and 3600 (1 hour); a default value of 300 (5 minutes) is used if no value is specified.
    This value and sasl.login.refresh.min.period.seconds are both ignored if their sum exceeds the remaining lifetime of a credential. Currently applies only to OAUTHBEARER.
  </description>
  <cn_description></cn_description>
  <type>short</type>
  <default>300</default>
  <valid_values>[0,...,3600]</valid_values>
  <importance>low</importance>
  <suggest></suggest>
</property>

<property>
  <name>sasl.login.refresh.min.period.seconds</name>
  <description>
    The desired minimum time for the login refresh thread to wait before refreshing a credential, in seconds.
    Legal values are between 0 and 900 (15 minutes); a default value of 60 (1 minute) is used if no value is specified.
    This value and sasl.login.refresh.buffer.seconds are both ignored if their sum exceeds the remaining lifetime of a credential. Currently applies only to OAUTHBEARER.
  </description>
  <cn_description></cn_description>
  <type>short</type>
  <default>60</default>
  <valid_values>[0,...,900]</valid_values>
  <importance>low</importance>
  <suggest></suggest>
</property>

<property>
  <name>sasl.login.refresh.window.factor</name>
  <description>
    Login refresh thread will sleep until the specified window factor relative to the credential's lifetime has been reached, at which time it will try to refresh the credential.
    Legal values are between 0.5 (50%) and 1.0 (100%) inclusive; a default value of 0.8 (80%) is used if no value is specified.
    Currently applies only to OAUTHBEARER.
  </description>
  <cn_description></cn_description>
  <type>double</type>
  <default>0.8</default>
  <valid_values>[0.5,...,1.0]</valid_values>
  <importance>low</importance>
  <suggest></suggest>
</property>

<property>
  <name>sasl.login.refresh.window.jitter</name>
  <description>
    The maximum amount of random jitter relative to the credential's lifetime that is added to the login refresh thread's sleep time.
    Legal values are between 0 and 0.25 (25%) inclusive; a default value of 0.05 (5%) is used if no value is specified. Currently applies only to OAUTHBEARER.
  </description>
  <cn_description></cn_description>
  <type>double</type>
  <default>0.05</default>
  <valid_values>[0.0,...,0.25]</valid_values>
  <importance>low</importance>
  <suggest></suggest>
</property>

<property>
  <name>ssl.cipher.suites</name>
  <description>
    A list of cipher suites.
    This is a named combination of authentication, encryption, MAC and key exchange algorithm used to negotiate the security settings for a network connection using TLS or SSL network protocol.
    By default all the available cipher suites are supported.
  </description>
  <cn_description></cn_description>
  <type>list</type>
  <default>null</default>
  <valid_values></valid_values>
  <importance>low</importance>
  <suggest></suggest>
</property>

<property>
  <name>ssl.endpoint.identification.algorithm</name>
  <description>
    The endpoint identification algorithm to validate server hostname using server certificate.
  </description>
  <cn_description></cn_description>
  <type>string</type>
  <default>https</default>
  <valid_values></valid_values>
  <importance>low</importance>
  <suggest></suggest>
</property>

<property>
  <name>ssl.keymanager.algorithm</name>
  <description>
    The algorithm used by key manager factory for SSL connections. Default value is the key manager factory algorithm configured for the Java Virtual Machine.
  </description>
  <cn_description></cn_description>
  <type>string</type>
  <default>SunX509</default>
  <valid_values></valid_values>
  <importance>low</importance>
  <suggest></suggest>
</property>

<property>
  <name>ssl.secure.random.implementation</name>
  <description>
    The SecureRandom PRNG implementation to use for SSL cryptography operations.
  </description>
  <cn_description></cn_description>
  <type>string</type>
  <default>null</default>
  <valid_values></valid_values>
  <importance>low</importance>
  <suggest></suggest>
</property>

<property>
  <name>ssl.trustmanager.algorithm</name>
  <description>
    The algorithm used by trust manager factory for SSL connections. Default value is the trust manager factory algorithm configured for the Java Virtual Machine.
  </description>
  <cn_description></cn_description>
  <type>string</type>
  <default>PKIX</default>
  <valid_values></valid_values>
  <importance>low</importance>
  <suggest></suggest>
</property>

</configuration>